# cg-sf-freeListings

## Web Scraping Odyssey: Craigslist & The Old Reader Exploration

### Introduction

Welcome to my personal project repository, where I share my adventure into the realm of web scraping and automation using Python. This project is a deep dive into extracting valuable information from the web, focusing on the "free" section of Craigslist in the San Francisco Bay Area and automating the login process for The Old Reader. It's a journey of learning, exploration, and application of Python skills in real-world scenarios.

### Project Overview

This project consists of two main parts:

- **Craigslist Free Section Scrape**: A script that navigates, scrapes, and extracts details from the first 250 listings in the Craigslist "free" section. It explores web scraping fundamentals, including page navigation, HTML content saving, and data extraction.
- **The Old Reader Login Automation**: A script that automates the login process to The Old Reader website, showcasing the automation of web forms and session management in Python.

### Technologies Used

- Python 3
- Libraries: `requests`, `BeautifulSoup4`, `lxml`, and others for web scraping and automation.

### Features

- Scrape and save HTML content from Craigslist.
- Extract and display details from saved HTML files.
- Automate login to The Old Reader.
- Session management for consecutive automated tasks.

### Getting Started

#### Prerequisites

- Python 3.6+
- pip for Python package management

#### Installation

Clone the repository to your local machine:

```bash
git clone https://github.com/[yourusername]/cg-sf-freeListings.git

Example: https://github.com/jaskeeratbrar/cg-sf-freeListings.git
cd web-scraping-odyssey

```


To start the Craigslist scraping:

```bash
python craigslist_scraper.py
```
